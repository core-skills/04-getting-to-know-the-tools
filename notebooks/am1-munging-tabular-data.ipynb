{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munging tabular data\n",
    "\n",
    "We're going to go through how to munge tabular data in more detail (and _slowly_). The aim is for you to get comfortable with the tools we're using:\n",
    "\n",
    "- [pandas](pandas.pydata.org) for data handling (our dataframe library)\n",
    "- [seaborn](seaborn.pydata.org) for _nice_ data visualization\n",
    "- [scipy](scipy.org) for scientific libraries (particularly `scipy.stats` which we'll use for fitting some more unusual probability distributions), and \n",
    "- [statsmodels](statsmodels.org) which gives us some more expressive curve fitting approaches\n",
    "\n",
    "The other aim is to get familiar with code-sharing workflows - so we will be doing pair programming for the duration of the day! _You will probably want to take a moment to look at the documentation of the libraries above - especially pandas_\n",
    "\n",
    "The other useful resource is Stack Overflow - if you have a question that sounds like 'how do I do {x}' then someone will probably have answered it on SO. Questions are also tagged by library so if you have a particular pandas question you can do something like going to https://stackoverflow.com/questions/tagged/pandas (just replace the 'pandas' in the URL with whatever library you're trying to use.\n",
    "\n",
    "Generally answers on SO are probably a lot closer to getting you up and running than the documentation. Once you get used to the library then the documentation is generally a quicker reference. We will cover strategies for getting help in class.\n",
    "\n",
    "## Git links\n",
    "\n",
    "We will be working through using GitHub and GitKraken to share code between pairs. We will go through all the workflow in detail in class but here are some useful links for reference:\n",
    "\n",
    "- GitKraken interface basics: https://support.gitkraken.com/start-here/interface\n",
    "- Staging and committing (save current state -> local history): https://support.gitkraken.com/working-with-commits/commits\n",
    "- Pushing and pulling (sync local history <-> GitHub history): https://support.gitkraken.com/working-with-repositories/pushing-and-pulling\n",
    "- Forking and pull requests (request to sync your GitHub history <-> someone else's history - requires a _review_):\n",
    "  - https://help.github.com/articles/about-forks/\n",
    "  - https://help.github.com/articles/creating-a-pull-request-from-a-fork/\n",
    "\n",
    "## Step 1: Reading my data\n",
    "\n",
    "In pairs work out how to read your data into a pandas dataframe.\n",
    "\n",
    "If you have your own tabular data please start using it here. If not, use the ATCO dataset from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've worked this out in the Jupyter notebook, transfer your code to a Python script (say a function called `load_data` in a file called `munging.py` in the same directory as the notebooks - you can create a text file in the Jupyter notebook home screen). Then try importing your load function with \n",
    "\n",
    "```python \n",
    "from munging import load_data\n",
    "\n",
    "df = load_data('path/to/datafile')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next work out how to access a column within your dataframe. \n",
    "\n",
    "- How can you list all the column names? \n",
    "- There are two ways to access columns by name - try to find out what both of these are. \n",
    "- There's also methods to access columns by number - try to do this as well\n",
    "\n",
    "Next look at how to access rows - both using labels and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access records efficiently pandas can construct an index for your data. Find out how you set the index on your dataframe and pick a useful column (i.e. one that has a unique value for each record and can be sorted) and set this as the index.\n",
    "\n",
    "Try selecting data using your index (especially if you have a timeseries index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get through this quickly, take a look at the [other data formats that pandas is able to read](http://pandas.pydata.org/pandas-docs/stable/api.html#input-output) and find out about these online - we can have a discussion about when you might like to use them. Pay particular attention to [`pandas.read_sql`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html#pandas.read_sql) as that's pretty useful for ripping data from databases.\n",
    "\n",
    "Go to [data.gov.au](https://data.gov.au) and find some other data in different formats to read and try reading it.\n",
    "\n",
    "## Step 2: What's in my data?\n",
    "\n",
    "First find the documentation in pandas on datatypes!\n",
    "\n",
    "Work through the columns in your dataset and assign them to the correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will you find incorrect values in your data? Can you write a small function to test these? For more details on Python functions you can work through [this little tutorial on DataCamp](https://www.datacamp.com/community/tutorials/functions-python-tutorial)\n",
    "\n",
    "Also take a look at the [`apply`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) method for more tricky data munging that has to be carried out record-by-record\n",
    "\n",
    "Try writing a small function to apply to one of the columns in your dataframe - here's a toy example to get you started: your function could look something like:\n",
    "\n",
    "```python\n",
    "import random\n",
    "import pandas\n",
    "\n",
    "# Define our bogus function\n",
    "def random_replacement(record):\n",
    "    \"Some of column 'a', some of column 'b'\"\n",
    "    return random.sample([record.a, record.b], 1)[0]\n",
    "\n",
    "# Make some bogus data\n",
    "nrows = 10\n",
    "df = pandas.DataFrame([[1, 2],] * nrows, \n",
    "                      columns=['a', 'b'])\n",
    "\n",
    "# Apply function once per record\n",
    "df.apply(random_replacement, axis='columns')\n",
    "\n",
    "# Apply function once per column\n",
    "df.apply(sum, axis='index')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Tidy my data\n",
    "\n",
    "Work through the 'tidy data checklist' and make sure your data has been tidied!\n",
    "\n",
    "This is a good overview: http://www.jeannicholashould.com/tidy-data-in-python.html\n",
    "\n",
    "If your data is already tidy, try downloading the data from that tutorial and working through it instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're done with this, copy your code from steps 2 and 3 over to a Python script for easier sharing. This is an example of an extract-transform-load workflow that you could share with your IT department to run automatically when your org collects more data that is similar to this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:week02]",
   "language": "python",
   "name": "conda-env-week02-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
